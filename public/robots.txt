# robots.txt for Rio Attractions
# This file tells search engine crawlers which pages to index

# Allow all crawlers
User-agent: *

# Allow all pages
Disallow:

# Sitemap location (generated by @astrojs/sitemap)
Sitemap: https://rio-attractions.example.com/sitemap-index.xml

# Crawl delay (be nice to our server)
Crawl-delay: 1
